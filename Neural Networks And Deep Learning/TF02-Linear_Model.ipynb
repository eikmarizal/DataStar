{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning and Neural Network: TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from display_tool import show_graph\n",
    "import tensorflow as tf\n",
    "\n",
    "# build a linear model where y = w * x + b\n",
    "\n",
    "w = tf.Variable([0.2], tf.float32, name='weight')\n",
    "b = tf.Variable([0.3], tf.float32, name='bias')\n",
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name=\"Xplace\")\n",
    "Y = tf.placeholder(tf.float32, name='Yplace')\n",
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the training values for x and y\n",
    "x = ([2.,3.,4.,5.])\n",
    "y = ([-1.,-2.,-3.,-4.])\n",
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.7368338152849303&quot;).pbtxt = 'node {\\n  name: &quot;weight/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;weight&quot;\\n  input: &quot;weight/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;weight&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.30000001192092896\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bias&quot;\\n  input: &quot;bias/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;weight_1&quot;\\n  input: &quot;weight_1/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;weight_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.30000001192092896\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bias_1&quot;\\n  input: &quot;bias_1/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bias_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xplace&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Yplace&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;weight_1/read&quot;\\n  input: &quot;Xplace&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;mul&quot;\\n  input: &quot;bias_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.7368338152849303&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # define the linear model\n",
    "linear_model = w*X+b\n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.7388371309202009&quot;).pbtxt = 'node {\\n  name: &quot;weight/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;weight&quot;\\n  input: &quot;weight/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;weight&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.30000001192092896\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bias&quot;\\n  input: &quot;bias/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;weight_1&quot;\\n  input: &quot;weight_1/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;weight_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.30000001192092896\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bias_1&quot;\\n  input: &quot;bias_1/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bias_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Xplace&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Yplace&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;weight_1/read&quot;\\n  input: &quot;Xplace&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;mul&quot;\\n  input: &quot;bias_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;add&quot;\\n  input: &quot;Yplace&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.7388371309202009&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the loss function\n",
    "square_delta = tf.square(linear_model - Y)\n",
    "show_graph(tf.get_default_graph().as_graph_def())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(square_delta)\n",
    "# show_graph(tf.get_default_graph().as_graph_def())\n",
    "#set the learning rate and training epoch\n",
    "learning_rate = 0.01\n",
    "training_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "# show_graph(tf.get_default_graph().as_graph_def())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start a session\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: -0.900000 b: 0.020000 loss: 1.637600 \n",
      "w: -0.733600 b: 0.070400 loss: 0.354876 \n",
      "w: -0.761024 b: 0.070176 loss: 0.320448 \n",
      "w: -0.758767 b: 0.077649 loss: 0.315325 \n",
      "w: -0.761040 b: 0.083892 loss: 0.310949 \n",
      "w: -0.762606 b: 0.090272 loss: 0.306648 \n",
      "w: -0.764268 b: 0.096580 loss: 0.302408 \n",
      "w: -0.765901 b: 0.102848 loss: 0.298226 \n",
      "w: -0.767525 b: 0.109073 loss: 0.294103 \n",
      "w: -0.769138 b: 0.115254 loss: 0.290036 \n",
      "w: -0.770740 b: 0.121392 loss: 0.286025 \n",
      "w: -0.772331 b: 0.127488 loss: 0.282070 \n",
      "w: -0.773910 b: 0.133542 loss: 0.278169 \n",
      "w: -0.775479 b: 0.139553 loss: 0.274323 \n",
      "w: -0.777037 b: 0.145523 loss: 0.270530 \n",
      "w: -0.778584 b: 0.151451 loss: 0.266789 \n",
      "w: -0.780120 b: 0.157339 loss: 0.263100 \n",
      "w: -0.781645 b: 0.163185 loss: 0.259461 \n",
      "w: -0.783160 b: 0.168991 loss: 0.255874 \n",
      "w: -0.784665 b: 0.174757 loss: 0.252335 \n",
      "w: -0.786159 b: 0.180482 loss: 0.248846 \n",
      "w: -0.787642 b: 0.186168 loss: 0.245405 \n",
      "w: -0.789116 b: 0.191814 loss: 0.242012 \n",
      "w: -0.790579 b: 0.197422 loss: 0.238665 \n",
      "w: -0.792032 b: 0.202990 loss: 0.235365 \n",
      "w: -0.793475 b: 0.208520 loss: 0.232110 \n",
      "w: -0.794908 b: 0.214011 loss: 0.228901 \n",
      "w: -0.796330 b: 0.219464 loss: 0.225735 \n",
      "w: -0.797743 b: 0.224880 loss: 0.222614 \n",
      "w: -0.799147 b: 0.230257 loss: 0.219536 \n",
      "w: -0.800540 b: 0.235598 loss: 0.216500 \n",
      "w: -0.801924 b: 0.240901 loss: 0.213506 \n",
      "w: -0.803298 b: 0.246168 loss: 0.210554 \n",
      "w: -0.804663 b: 0.251398 loss: 0.207642 \n",
      "w: -0.806018 b: 0.256592 loss: 0.204771 \n",
      "w: -0.807364 b: 0.261750 loss: 0.201940 \n",
      "w: -0.808701 b: 0.266872 loss: 0.199147 \n",
      "w: -0.810028 b: 0.271958 loss: 0.196393 \n",
      "w: -0.811346 b: 0.277009 loss: 0.193678 \n",
      "w: -0.812655 b: 0.282026 loss: 0.190999 \n",
      "w: -0.813955 b: 0.287007 loss: 0.188358 \n",
      "w: -0.815246 b: 0.291954 loss: 0.185754 \n",
      "w: -0.816527 b: 0.296866 loss: 0.183185 \n",
      "w: -0.817800 b: 0.301745 loss: 0.180652 \n",
      "w: -0.819064 b: 0.306589 loss: 0.178154 \n",
      "w: -0.820320 b: 0.311400 loss: 0.175690 \n",
      "w: -0.821566 b: 0.316178 loss: 0.173261 \n",
      "w: -0.822804 b: 0.320922 loss: 0.170865 \n",
      "w: -0.824034 b: 0.325633 loss: 0.168502 \n",
      "w: -0.825255 b: 0.330312 loss: 0.166172 \n",
      "w: -0.826467 b: 0.334958 loss: 0.163875 \n",
      "w: -0.827671 b: 0.339573 loss: 0.161609 \n",
      "w: -0.828867 b: 0.344155 loss: 0.159374 \n",
      "w: -0.830054 b: 0.348705 loss: 0.157170 \n",
      "w: -0.831233 b: 0.353224 loss: 0.154997 \n",
      "w: -0.832404 b: 0.357711 loss: 0.152853 \n",
      "w: -0.833567 b: 0.362167 loss: 0.150740 \n",
      "w: -0.834722 b: 0.366593 loss: 0.148655 \n",
      "w: -0.835868 b: 0.370987 loss: 0.146600 \n",
      "w: -0.837007 b: 0.375351 loss: 0.144572 \n",
      "w: -0.838138 b: 0.379685 loss: 0.142573 \n",
      "w: -0.839261 b: 0.383989 loss: 0.140602 \n",
      "w: -0.840376 b: 0.388263 loss: 0.138658 \n",
      "w: -0.841483 b: 0.392507 loss: 0.136740 \n",
      "w: -0.842583 b: 0.396722 loss: 0.134849 \n",
      "w: -0.843675 b: 0.400908 loss: 0.132985 \n",
      "w: -0.844760 b: 0.405064 loss: 0.131146 \n",
      "w: -0.845837 b: 0.409192 loss: 0.129332 \n",
      "w: -0.846907 b: 0.413291 loss: 0.127544 \n",
      "w: -0.847969 b: 0.417361 loss: 0.125780 \n",
      "w: -0.849024 b: 0.421404 loss: 0.124041 \n",
      "w: -0.850071 b: 0.425418 loss: 0.122326 \n",
      "w: -0.851111 b: 0.429405 loss: 0.120634 \n",
      "w: -0.852144 b: 0.433363 loss: 0.118966 \n",
      "w: -0.853170 b: 0.437295 loss: 0.117321 \n",
      "w: -0.854189 b: 0.441199 loss: 0.115699 \n",
      "w: -0.855201 b: 0.445076 loss: 0.114099 \n",
      "w: -0.856205 b: 0.448926 loss: 0.112521 \n",
      "w: -0.857203 b: 0.452749 loss: 0.110965 \n",
      "w: -0.858194 b: 0.456546 loss: 0.109431 \n",
      "w: -0.859177 b: 0.460317 loss: 0.107918 \n",
      "w: -0.860154 b: 0.464061 loss: 0.106425 \n",
      "w: -0.861125 b: 0.467779 loss: 0.104954 \n",
      "w: -0.862088 b: 0.471472 loss: 0.103502 \n",
      "w: -0.863045 b: 0.475139 loss: 0.102071 \n",
      "w: -0.863995 b: 0.478780 loss: 0.100660 \n",
      "w: -0.864939 b: 0.482397 loss: 0.099268 \n",
      "w: -0.865876 b: 0.485988 loss: 0.097895 \n",
      "w: -0.866806 b: 0.489554 loss: 0.096541 \n",
      "w: -0.867731 b: 0.493096 loss: 0.095206 \n",
      "w: -0.868648 b: 0.496612 loss: 0.093890 \n",
      "w: -0.869560 b: 0.500105 loss: 0.092592 \n",
      "w: -0.870465 b: 0.503573 loss: 0.091311 \n",
      "w: -0.871363 b: 0.507018 loss: 0.090049 \n",
      "w: -0.872256 b: 0.510438 loss: 0.088803 \n",
      "w: -0.873142 b: 0.513835 loss: 0.087575 \n",
      "w: -0.874022 b: 0.517208 loss: 0.086365 \n",
      "w: -0.874896 b: 0.520557 loss: 0.085170 \n",
      "w: -0.875764 b: 0.523884 loss: 0.083992 \n",
      "w: -0.876626 b: 0.527187 loss: 0.082831 \n",
      "w: -0.877482 b: 0.530467 loss: 0.081686 \n",
      "w: -0.878332 b: 0.533725 loss: 0.080556 \n",
      "w: -0.879176 b: 0.536960 loss: 0.079442 \n",
      "w: -0.880015 b: 0.540173 loss: 0.078344 \n",
      "w: -0.880847 b: 0.543363 loss: 0.077260 \n",
      "w: -0.881674 b: 0.546531 loss: 0.076192 \n",
      "w: -0.882495 b: 0.549677 loss: 0.075138 \n",
      "w: -0.883310 b: 0.552802 loss: 0.074099 \n",
      "w: -0.884120 b: 0.555904 loss: 0.073075 \n",
      "w: -0.884924 b: 0.558985 loss: 0.072064 \n",
      "w: -0.885722 b: 0.562045 loss: 0.071068 \n",
      "w: -0.886515 b: 0.565084 loss: 0.070085 \n",
      "w: -0.887302 b: 0.568101 loss: 0.069116 \n",
      "w: -0.888084 b: 0.571098 loss: 0.068160 \n",
      "w: -0.888861 b: 0.574074 loss: 0.067218 \n",
      "w: -0.889632 b: 0.577029 loss: 0.066288 \n",
      "w: -0.890397 b: 0.579963 loss: 0.065372 \n",
      "w: -0.891158 b: 0.582877 loss: 0.064468 \n",
      "w: -0.891913 b: 0.585772 loss: 0.063576 \n",
      "w: -0.892663 b: 0.588645 loss: 0.062697 \n",
      "w: -0.893408 b: 0.591499 loss: 0.061830 \n",
      "w: -0.894147 b: 0.594334 loss: 0.060975 \n",
      "w: -0.894882 b: 0.597148 loss: 0.060132 \n",
      "w: -0.895611 b: 0.599943 loss: 0.059300 \n",
      "w: -0.896335 b: 0.602719 loss: 0.058480 \n",
      "w: -0.897054 b: 0.605475 loss: 0.057672 \n",
      "w: -0.897769 b: 0.608212 loss: 0.056874 \n",
      "w: -0.898478 b: 0.610931 loss: 0.056088 \n",
      "w: -0.899182 b: 0.613630 loss: 0.055312 \n",
      "w: -0.899882 b: 0.616311 loss: 0.054547 \n",
      "w: -0.900576 b: 0.618973 loss: 0.053793 \n",
      "w: -0.901266 b: 0.621616 loss: 0.053049 \n",
      "w: -0.901951 b: 0.624241 loss: 0.052316 \n",
      "w: -0.902632 b: 0.626849 loss: 0.051592 \n",
      "w: -0.903307 b: 0.629437 loss: 0.050879 \n",
      "w: -0.903978 b: 0.632008 loss: 0.050175 \n",
      "w: -0.904644 b: 0.634562 loss: 0.049481 \n",
      "w: -0.905306 b: 0.637097 loss: 0.048797 \n",
      "w: -0.905963 b: 0.639615 loss: 0.048122 \n",
      "w: -0.906615 b: 0.642115 loss: 0.047457 \n",
      "w: -0.907263 b: 0.644598 loss: 0.046801 \n",
      "w: -0.907906 b: 0.647064 loss: 0.046154 \n",
      "w: -0.908545 b: 0.649513 loss: 0.045516 \n",
      "w: -0.909180 b: 0.651944 loss: 0.044886 \n",
      "w: -0.909810 b: 0.654359 loss: 0.044265 \n",
      "w: -0.910436 b: 0.656757 loss: 0.043653 \n",
      "w: -0.911057 b: 0.659139 loss: 0.043050 \n",
      "w: -0.911674 b: 0.661504 loss: 0.042454 \n",
      "w: -0.912287 b: 0.663852 loss: 0.041867 \n",
      "w: -0.912896 b: 0.666184 loss: 0.041288 \n",
      "w: -0.913500 b: 0.668500 loss: 0.040717 \n",
      "w: -0.914100 b: 0.670800 loss: 0.040154 \n",
      "w: -0.914696 b: 0.673084 loss: 0.039599 \n",
      "w: -0.915288 b: 0.675352 loss: 0.039052 \n",
      "w: -0.915876 b: 0.677605 loss: 0.038512 \n",
      "w: -0.916459 b: 0.679842 loss: 0.037979 \n",
      "w: -0.917039 b: 0.682063 loss: 0.037454 \n",
      "w: -0.917614 b: 0.684269 loss: 0.036936 \n",
      "w: -0.918186 b: 0.686459 loss: 0.036425 \n",
      "w: -0.918754 b: 0.688635 loss: 0.035922 \n",
      "w: -0.919317 b: 0.690795 loss: 0.035425 \n",
      "w: -0.919877 b: 0.692940 loss: 0.034935 \n",
      "w: -0.920433 b: 0.695071 loss: 0.034452 \n",
      "w: -0.920985 b: 0.697186 loss: 0.033975 \n",
      "w: -0.921533 b: 0.699287 loss: 0.033506 \n",
      "w: -0.922078 b: 0.701373 loss: 0.033042 \n",
      "w: -0.922618 b: 0.703445 loss: 0.032585 \n",
      "w: -0.923155 b: 0.705503 loss: 0.032135 \n",
      "w: -0.923688 b: 0.707546 loss: 0.031690 \n",
      "w: -0.924218 b: 0.709575 loss: 0.031252 \n",
      "w: -0.924744 b: 0.711590 loss: 0.030820 \n",
      "w: -0.925266 b: 0.713591 loss: 0.030394 \n",
      "w: -0.925784 b: 0.715578 loss: 0.029974 \n",
      "w: -0.926299 b: 0.717552 loss: 0.029559 \n",
      "w: -0.926811 b: 0.719511 loss: 0.029150 \n",
      "w: -0.927318 b: 0.721457 loss: 0.028747 \n",
      "w: -0.927823 b: 0.723390 loss: 0.028350 \n",
      "w: -0.928323 b: 0.725309 loss: 0.027958 \n",
      "w: -0.928821 b: 0.727215 loss: 0.027571 \n",
      "w: -0.929314 b: 0.729107 loss: 0.027190 \n",
      "w: -0.929805 b: 0.730987 loss: 0.026814 \n",
      "w: -0.930292 b: 0.732853 loss: 0.026443 \n",
      "w: -0.930776 b: 0.734707 loss: 0.026078 \n",
      "w: -0.931256 b: 0.736547 loss: 0.025717 \n",
      "w: -0.931733 b: 0.738375 loss: 0.025361 \n",
      "w: -0.932206 b: 0.740190 loss: 0.025011 \n",
      "w: -0.932677 b: 0.741993 loss: 0.024665 \n",
      "w: -0.933144 b: 0.743783 loss: 0.024324 \n",
      "w: -0.933608 b: 0.745561 loss: 0.023987 \n",
      "w: -0.934068 b: 0.747326 loss: 0.023656 \n",
      "w: -0.934526 b: 0.749079 loss: 0.023329 \n",
      "w: -0.934980 b: 0.750820 loss: 0.023006 \n",
      "w: -0.935431 b: 0.752549 loss: 0.022688 \n",
      "w: -0.935879 b: 0.754266 loss: 0.022374 \n",
      "w: -0.936324 b: 0.755970 loss: 0.022065 \n",
      "w: -0.936766 b: 0.757664 loss: 0.021760 \n",
      "w: -0.937205 b: 0.759345 loss: 0.021459 \n",
      "w: -0.937640 b: 0.761015 loss: 0.021162 \n",
      "w: -0.938073 b: 0.762673 loss: 0.020869 \n",
      "w: -0.938502 b: 0.764319 loss: 0.020581 \n",
      "w: -0.938929 b: 0.765954 loss: 0.020296 \n",
      "w: -0.939353 b: 0.767578 loss: 0.020016 \n",
      "w: -0.939774 b: 0.769191 loss: 0.019739 \n",
      "w: -0.940192 b: 0.770792 loss: 0.019466 \n",
      "w: -0.940606 b: 0.772382 loss: 0.019197 \n",
      "w: -0.941019 b: 0.773962 loss: 0.018931 \n",
      "w: -0.941428 b: 0.775530 loss: 0.018669 \n",
      "w: -0.941834 b: 0.777087 loss: 0.018411 \n",
      "w: -0.942238 b: 0.778634 loss: 0.018157 \n",
      "w: -0.942638 b: 0.780170 loss: 0.017906 \n",
      "w: -0.943036 b: 0.781695 loss: 0.017658 \n",
      "w: -0.943432 b: 0.783209 loss: 0.017414 \n",
      "w: -0.943824 b: 0.784714 loss: 0.017173 \n",
      "w: -0.944214 b: 0.786207 loss: 0.016936 \n",
      "w: -0.944601 b: 0.787691 loss: 0.016701 \n",
      "w: -0.944985 b: 0.789164 loss: 0.016470 \n",
      "w: -0.945367 b: 0.790626 loss: 0.016243 \n",
      "w: -0.945746 b: 0.792079 loss: 0.016018 \n",
      "w: -0.946122 b: 0.793522 loss: 0.015797 \n",
      "w: -0.946496 b: 0.794954 loss: 0.015578 \n",
      "w: -0.946867 b: 0.796377 loss: 0.015363 \n",
      "w: -0.947236 b: 0.797790 loss: 0.015150 \n",
      "w: -0.947602 b: 0.799192 loss: 0.014941 \n",
      "w: -0.947966 b: 0.800586 loss: 0.014734 \n",
      "w: -0.948327 b: 0.801969 loss: 0.014530 \n",
      "w: -0.948685 b: 0.803343 loss: 0.014330 \n",
      "w: -0.949041 b: 0.804708 loss: 0.014131 \n",
      "w: -0.949395 b: 0.806062 loss: 0.013936 \n",
      "w: -0.949746 b: 0.807408 loss: 0.013743 \n",
      "w: -0.950095 b: 0.808744 loss: 0.013553 \n",
      "w: -0.950441 b: 0.810071 loss: 0.013366 \n",
      "w: -0.950785 b: 0.811389 loss: 0.013181 \n",
      "w: -0.951126 b: 0.812698 loss: 0.012999 \n",
      "w: -0.951465 b: 0.813997 loss: 0.012819 \n",
      "w: -0.951802 b: 0.815288 loss: 0.012642 \n",
      "w: -0.952136 b: 0.816569 loss: 0.012467 \n",
      "w: -0.952468 b: 0.817842 loss: 0.012295 \n",
      "w: -0.952798 b: 0.819106 loss: 0.012125 \n",
      "w: -0.953126 b: 0.820361 loss: 0.011957 \n",
      "w: -0.953451 b: 0.821607 loss: 0.011792 \n",
      "w: -0.953774 b: 0.822845 loss: 0.011628 \n",
      "w: -0.954095 b: 0.824074 loss: 0.011468 \n",
      "w: -0.954413 b: 0.825294 loss: 0.011309 \n",
      "w: -0.954729 b: 0.826506 loss: 0.011153 \n",
      "w: -0.955043 b: 0.827710 loss: 0.010999 \n",
      "w: -0.955355 b: 0.828906 loss: 0.010846 \n",
      "w: -0.955665 b: 0.830093 loss: 0.010696 \n",
      "w: -0.955973 b: 0.831271 loss: 0.010549 \n",
      "w: -0.956278 b: 0.832442 loss: 0.010403 \n",
      "w: -0.956582 b: 0.833605 loss: 0.010259 \n",
      "w: -0.956883 b: 0.834759 loss: 0.010117 \n",
      "w: -0.957182 b: 0.835905 loss: 0.009977 \n",
      "w: -0.957479 b: 0.837044 loss: 0.009839 \n",
      "w: -0.957774 b: 0.838175 loss: 0.009703 \n",
      "w: -0.958067 b: 0.839297 loss: 0.009569 \n",
      "w: -0.958358 b: 0.840412 loss: 0.009437 \n",
      "w: -0.958647 b: 0.841520 loss: 0.009306 \n",
      "w: -0.958934 b: 0.842619 loss: 0.009177 \n",
      "w: -0.959219 b: 0.843711 loss: 0.009050 \n",
      "w: -0.959502 b: 0.844795 loss: 0.008925 \n",
      "w: -0.959783 b: 0.845872 loss: 0.008802 \n",
      "w: -0.960062 b: 0.846941 loss: 0.008680 \n",
      "w: -0.960339 b: 0.848003 loss: 0.008560 \n",
      "w: -0.960614 b: 0.849058 loss: 0.008442 \n",
      "w: -0.960887 b: 0.850105 loss: 0.008325 \n",
      "w: -0.961158 b: 0.851145 loss: 0.008210 \n",
      "w: -0.961428 b: 0.852178 loss: 0.008096 \n",
      "w: -0.961696 b: 0.853204 loss: 0.007984 \n",
      "w: -0.961961 b: 0.854222 loss: 0.007874 \n",
      "w: -0.962225 b: 0.855233 loss: 0.007765 \n",
      "w: -0.962487 b: 0.856238 loss: 0.007658 \n",
      "w: -0.962748 b: 0.857235 loss: 0.007552 \n",
      "w: -0.963006 b: 0.858226 loss: 0.007447 \n",
      "w: -0.963263 b: 0.859209 loss: 0.007344 \n",
      "w: -0.963518 b: 0.860186 loss: 0.007243 \n",
      "w: -0.963771 b: 0.861156 loss: 0.007143 \n",
      "w: -0.964022 b: 0.862119 loss: 0.007044 \n",
      "w: -0.964272 b: 0.863076 loss: 0.006947 \n",
      "w: -0.964520 b: 0.864026 loss: 0.006851 \n",
      "w: -0.964766 b: 0.864970 loss: 0.006756 \n",
      "w: -0.965010 b: 0.865906 loss: 0.006662 \n",
      "w: -0.965253 b: 0.866837 loss: 0.006570 \n",
      "w: -0.965494 b: 0.867761 loss: 0.006479 \n",
      "w: -0.965733 b: 0.868678 loss: 0.006390 \n",
      "w: -0.965971 b: 0.869589 loss: 0.006301 \n",
      "w: -0.966207 b: 0.870494 loss: 0.006214 \n",
      "w: -0.966442 b: 0.871393 loss: 0.006128 \n",
      "w: -0.966675 b: 0.872285 loss: 0.006044 \n",
      "w: -0.966906 b: 0.873171 loss: 0.005960 \n",
      "w: -0.967135 b: 0.874051 loss: 0.005878 \n",
      "w: -0.967363 b: 0.874925 loss: 0.005796 \n",
      "w: -0.967590 b: 0.875793 loss: 0.005716 \n",
      "w: -0.967815 b: 0.876654 loss: 0.005637 \n",
      "w: -0.968038 b: 0.877510 loss: 0.005559 \n",
      "w: -0.968260 b: 0.878360 loss: 0.005482 \n",
      "w: -0.968480 b: 0.879204 loss: 0.005407 \n",
      "w: -0.968699 b: 0.880042 loss: 0.005332 \n",
      "w: -0.968916 b: 0.880874 loss: 0.005258 \n",
      "w: -0.969132 b: 0.881701 loss: 0.005185 \n",
      "w: -0.969346 b: 0.882521 loss: 0.005114 \n",
      "w: -0.969558 b: 0.883337 loss: 0.005043 \n",
      "w: -0.969770 b: 0.884146 loss: 0.004973 \n",
      "w: -0.969979 b: 0.884950 loss: 0.004904 \n",
      "w: -0.970188 b: 0.885748 loss: 0.004837 \n",
      "w: -0.970394 b: 0.886541 loss: 0.004770 \n",
      "w: -0.970600 b: 0.887328 loss: 0.004704 \n",
      "w: -0.970804 b: 0.888110 loss: 0.004639 \n",
      "w: -0.971006 b: 0.888886 loss: 0.004575 \n",
      "w: -0.971208 b: 0.889657 loss: 0.004511 \n",
      "w: -0.971407 b: 0.890422 loss: 0.004449 \n",
      "w: -0.971606 b: 0.891183 loss: 0.004387 \n",
      "w: -0.971803 b: 0.891938 loss: 0.004327 \n",
      "w: -0.971998 b: 0.892687 loss: 0.004267 \n",
      "w: -0.972193 b: 0.893432 loss: 0.004208 \n",
      "w: -0.972386 b: 0.894171 loss: 0.004150 \n",
      "w: -0.972577 b: 0.894906 loss: 0.004092 \n",
      "w: -0.972767 b: 0.895635 loss: 0.004036 \n",
      "w: -0.972956 b: 0.896359 loss: 0.003980 \n",
      "w: -0.973144 b: 0.897078 loss: 0.003925 \n",
      "w: -0.973330 b: 0.897792 loss: 0.003871 \n",
      "w: -0.973515 b: 0.898501 loss: 0.003817 \n",
      "w: -0.973699 b: 0.899205 loss: 0.003764 \n",
      "w: -0.973882 b: 0.899905 loss: 0.003712 \n",
      "w: -0.974063 b: 0.900599 loss: 0.003661 \n",
      "w: -0.974243 b: 0.901289 loss: 0.003610 \n",
      "w: -0.974421 b: 0.901973 loss: 0.003560 \n",
      "w: -0.974599 b: 0.902654 loss: 0.003511 \n",
      "w: -0.974775 b: 0.903329 loss: 0.003463 \n",
      "w: -0.974950 b: 0.904000 loss: 0.003415 \n",
      "w: -0.975124 b: 0.904666 loss: 0.003368 \n",
      "w: -0.975296 b: 0.905327 loss: 0.003321 \n",
      "w: -0.975468 b: 0.905984 loss: 0.003275 \n",
      "w: -0.975638 b: 0.906636 loss: 0.003230 \n",
      "w: -0.975807 b: 0.907284 loss: 0.003185 \n",
      "w: -0.975975 b: 0.907927 loss: 0.003141 \n",
      "w: -0.976142 b: 0.908566 loss: 0.003098 \n",
      "w: -0.976307 b: 0.909200 loss: 0.003055 \n",
      "w: -0.976472 b: 0.909830 loss: 0.003013 \n",
      "w: -0.976635 b: 0.910456 loss: 0.002971 \n",
      "w: -0.976797 b: 0.911077 loss: 0.002930 \n",
      "w: -0.976958 b: 0.911694 loss: 0.002889 \n",
      "w: -0.977118 b: 0.912307 loss: 0.002849 \n",
      "w: -0.977277 b: 0.912915 loss: 0.002810 \n",
      "w: -0.977434 b: 0.913520 loss: 0.002771 \n",
      "w: -0.977591 b: 0.914120 loss: 0.002733 \n",
      "w: -0.977746 b: 0.914715 loss: 0.002695 \n",
      "w: -0.977901 b: 0.915307 loss: 0.002658 \n",
      "w: -0.978054 b: 0.915895 loss: 0.002621 \n",
      "w: -0.978206 b: 0.916478 loss: 0.002585 \n",
      "w: -0.978357 b: 0.917058 loss: 0.002549 \n",
      "w: -0.978508 b: 0.917633 loss: 0.002514 \n",
      "w: -0.978657 b: 0.918205 loss: 0.002479 \n",
      "w: -0.978805 b: 0.918772 loss: 0.002445 \n",
      "w: -0.978952 b: 0.919336 loss: 0.002411 \n",
      "w: -0.979098 b: 0.919895 loss: 0.002378 \n",
      "w: -0.979243 b: 0.920451 loss: 0.002345 \n",
      "w: -0.979387 b: 0.921003 loss: 0.002312 \n",
      "w: -0.979530 b: 0.921551 loss: 0.002280 \n",
      "w: -0.979672 b: 0.922095 loss: 0.002249 \n",
      "w: -0.979813 b: 0.922636 loss: 0.002218 \n",
      "w: -0.979953 b: 0.923173 loss: 0.002187 \n",
      "w: -0.980092 b: 0.923706 loss: 0.002157 \n",
      "w: -0.980230 b: 0.924235 loss: 0.002127 \n",
      "w: -0.980367 b: 0.924761 loss: 0.002098 \n",
      "w: -0.980504 b: 0.925283 loss: 0.002068 \n",
      "w: -0.980639 b: 0.925801 loss: 0.002040 \n",
      "w: -0.980773 b: 0.926316 loss: 0.002012 \n",
      "w: -0.980907 b: 0.926827 loss: 0.001984 \n",
      "w: -0.981039 b: 0.927335 loss: 0.001956 \n",
      "w: -0.981171 b: 0.927839 loss: 0.001929 \n",
      "w: -0.981301 b: 0.928340 loss: 0.001903 \n",
      "w: -0.981431 b: 0.928837 loss: 0.001876 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: -0.981560 b: 0.929331 loss: 0.001850 \n",
      "w: -0.981688 b: 0.929821 loss: 0.001825 \n",
      "w: -0.981815 b: 0.930308 loss: 0.001800 \n",
      "w: -0.981941 b: 0.930791 loss: 0.001775 \n",
      "w: -0.982066 b: 0.931271 loss: 0.001750 \n",
      "w: -0.982191 b: 0.931748 loss: 0.001726 \n",
      "w: -0.982314 b: 0.932222 loss: 0.001702 \n",
      "w: -0.982437 b: 0.932692 loss: 0.001679 \n",
      "w: -0.982559 b: 0.933159 loss: 0.001655 \n",
      "w: -0.982680 b: 0.933623 loss: 0.001632 \n",
      "w: -0.982800 b: 0.934083 loss: 0.001610 \n",
      "w: -0.982919 b: 0.934541 loss: 0.001588 \n",
      "w: -0.983038 b: 0.934995 loss: 0.001566 \n",
      "w: -0.983156 b: 0.935446 loss: 0.001544 \n",
      "w: -0.983272 b: 0.935894 loss: 0.001523 \n",
      "w: -0.983388 b: 0.936338 loss: 0.001502 \n",
      "w: -0.983504 b: 0.936780 loss: 0.001481 \n",
      "w: -0.983618 b: 0.937219 loss: 0.001460 \n",
      "w: -0.983732 b: 0.937654 loss: 0.001440 \n",
      "w: -0.983845 b: 0.938087 loss: 0.001420 \n",
      "w: -0.983957 b: 0.938517 loss: 0.001401 \n",
      "w: -0.984068 b: 0.938943 loss: 0.001381 \n",
      "w: -0.984179 b: 0.939367 loss: 0.001362 \n",
      "w: -0.984288 b: 0.939787 loss: 0.001343 \n",
      "w: -0.984397 b: 0.940205 loss: 0.001325 \n",
      "w: -0.984506 b: 0.940620 loss: 0.001306 \n",
      "w: -0.984613 b: 0.941032 loss: 0.001288 \n",
      "w: -0.984720 b: 0.941441 loss: 0.001271 \n",
      "w: -0.984826 b: 0.941847 loss: 0.001253 \n",
      "w: -0.984931 b: 0.942251 loss: 0.001236 \n",
      "w: -0.985036 b: 0.942652 loss: 0.001219 \n",
      "w: -0.985140 b: 0.943049 loss: 0.001202 \n",
      "w: -0.985243 b: 0.943445 loss: 0.001185 \n",
      "w: -0.985345 b: 0.943837 loss: 0.001169 \n",
      "w: -0.985447 b: 0.944227 loss: 0.001153 \n",
      "w: -0.985548 b: 0.944614 loss: 0.001137 \n",
      "w: -0.985648 b: 0.944998 loss: 0.001121 \n",
      "w: -0.985748 b: 0.945379 loss: 0.001105 \n",
      "w: -0.985846 b: 0.945758 loss: 0.001090 \n",
      "w: -0.985945 b: 0.946135 loss: 0.001075 \n",
      "w: -0.986042 b: 0.946508 loss: 0.001060 \n",
      "w: -0.986139 b: 0.946880 loss: 0.001046 \n",
      "w: -0.986235 b: 0.947248 loss: 0.001031 \n",
      "w: -0.986331 b: 0.947614 loss: 0.001017 \n",
      "w: -0.986426 b: 0.947978 loss: 0.001003 \n",
      "w: -0.986520 b: 0.948339 loss: 0.000989 \n",
      "w: -0.986613 b: 0.948697 loss: 0.000975 \n",
      "w: -0.986706 b: 0.949053 loss: 0.000962 \n",
      "w: -0.986798 b: 0.949406 loss: 0.000948 \n",
      "w: -0.986890 b: 0.949757 loss: 0.000935 \n",
      "w: -0.986981 b: 0.950106 loss: 0.000922 \n",
      "w: -0.987071 b: 0.950452 loss: 0.000910 \n",
      "w: -0.987161 b: 0.950796 loss: 0.000897 \n",
      "w: -0.987250 b: 0.951137 loss: 0.000885 \n",
      "w: -0.987338 b: 0.951476 loss: 0.000872 \n",
      "w: -0.987426 b: 0.951813 loss: 0.000860 \n",
      "w: -0.987514 b: 0.952147 loss: 0.000848 \n",
      "w: -0.987600 b: 0.952479 loss: 0.000837 \n",
      "w: -0.987686 b: 0.952809 loss: 0.000825 \n",
      "w: -0.987772 b: 0.953136 loss: 0.000814 \n",
      "w: -0.987856 b: 0.953462 loss: 0.000802 \n",
      "w: -0.987941 b: 0.953784 loss: 0.000791 \n",
      "w: -0.988024 b: 0.954105 loss: 0.000780 \n",
      "w: -0.988107 b: 0.954423 loss: 0.000770 \n",
      "w: -0.988190 b: 0.954740 loss: 0.000759 \n",
      "w: -0.988272 b: 0.955054 loss: 0.000749 \n",
      "w: -0.988353 b: 0.955365 loss: 0.000738 \n",
      "w: -0.988434 b: 0.955675 loss: 0.000728 \n",
      "w: -0.988514 b: 0.955983 loss: 0.000718 \n",
      "w: -0.988594 b: 0.956288 loss: 0.000708 \n",
      "w: -0.988673 b: 0.956591 loss: 0.000698 \n",
      "w: -0.988752 b: 0.956893 loss: 0.000689 \n",
      "w: -0.988830 b: 0.957192 loss: 0.000679 \n",
      "w: -0.988907 b: 0.957489 loss: 0.000670 \n",
      "w: -0.988984 b: 0.957784 loss: 0.000660 \n",
      "w: -0.989061 b: 0.958076 loss: 0.000651 \n",
      "w: -0.989137 b: 0.958367 loss: 0.000642 \n",
      "w: -0.989212 b: 0.958656 loss: 0.000633 \n",
      "w: -0.989287 b: 0.958943 loss: 0.000625 \n",
      "w: -0.989361 b: 0.959228 loss: 0.000616 \n",
      "w: -0.989435 b: 0.959511 loss: 0.000607 \n",
      "w: -0.989508 b: 0.959792 loss: 0.000599 \n",
      "w: -0.989581 b: 0.960071 loss: 0.000591 \n",
      "w: -0.989653 b: 0.960348 loss: 0.000583 \n",
      "w: -0.989725 b: 0.960623 loss: 0.000575 \n",
      "w: -0.989796 b: 0.960896 loss: 0.000567 \n",
      "w: -0.989867 b: 0.961167 loss: 0.000559 \n",
      "w: -0.989937 b: 0.961437 loss: 0.000551 \n",
      "w: -0.990007 b: 0.961704 loss: 0.000543 \n",
      "w: -0.990077 b: 0.961970 loss: 0.000536 \n",
      "w: -0.990145 b: 0.962234 loss: 0.000528 \n",
      "w: -0.990214 b: 0.962496 loss: 0.000521 \n",
      "w: -0.990282 b: 0.962756 loss: 0.000514 \n",
      "w: -0.990349 b: 0.963014 loss: 0.000507 \n",
      "w: -0.990416 b: 0.963271 loss: 0.000500 \n",
      "w: -0.990483 b: 0.963526 loss: 0.000493 \n",
      "w: -0.990549 b: 0.963779 loss: 0.000486 \n",
      "w: -0.990614 b: 0.964030 loss: 0.000479 \n",
      "w: -0.990679 b: 0.964280 loss: 0.000473 \n",
      "w: -0.990744 b: 0.964528 loss: 0.000466 \n",
      "w: -0.990808 b: 0.964774 loss: 0.000460 \n",
      "w: -0.990872 b: 0.965018 loss: 0.000453 \n",
      "w: -0.990935 b: 0.965261 loss: 0.000447 \n",
      "w: -0.990998 b: 0.965502 loss: 0.000441 \n",
      "w: -0.991061 b: 0.965741 loss: 0.000435 \n",
      "w: -0.991123 b: 0.965979 loss: 0.000429 \n",
      "w: -0.991184 b: 0.966215 loss: 0.000423 \n",
      "w: -0.991245 b: 0.966449 loss: 0.000417 \n",
      "w: -0.991306 b: 0.966682 loss: 0.000411 \n",
      "w: -0.991366 b: 0.966913 loss: 0.000406 \n",
      "w: -0.991426 b: 0.967143 loss: 0.000400 \n",
      "w: -0.991486 b: 0.967371 loss: 0.000394 \n",
      "w: -0.991545 b: 0.967597 loss: 0.000389 \n",
      "w: -0.991604 b: 0.967822 loss: 0.000384 \n",
      "w: -0.991662 b: 0.968045 loss: 0.000378 \n",
      "w: -0.991720 b: 0.968267 loss: 0.000373 \n",
      "w: -0.991777 b: 0.968487 loss: 0.000368 \n",
      "w: -0.991834 b: 0.968706 loss: 0.000363 \n",
      "w: -0.991891 b: 0.968923 loss: 0.000358 \n",
      "w: -0.991947 b: 0.969138 loss: 0.000353 \n",
      "w: -0.992003 b: 0.969353 loss: 0.000348 \n",
      "w: -0.992058 b: 0.969565 loss: 0.000343 \n",
      "w: -0.992114 b: 0.969776 loss: 0.000338 \n",
      "w: -0.992168 b: 0.969986 loss: 0.000334 \n",
      "w: -0.992223 b: 0.970194 loss: 0.000329 \n",
      "w: -0.992277 b: 0.970401 loss: 0.000325 \n",
      "w: -0.992330 b: 0.970606 loss: 0.000320 \n",
      "w: -0.992383 b: 0.970810 loss: 0.000316 \n",
      "w: -0.992436 b: 0.971013 loss: 0.000311 \n",
      "w: -0.992489 b: 0.971214 loss: 0.000307 \n",
      "w: -0.992541 b: 0.971414 loss: 0.000303 \n",
      "w: -0.992593 b: 0.971612 loss: 0.000299 \n",
      "w: -0.992644 b: 0.971809 loss: 0.000294 \n",
      "w: -0.992695 b: 0.972005 loss: 0.000290 \n",
      "w: -0.992746 b: 0.972199 loss: 0.000286 \n",
      "w: -0.992796 b: 0.972392 loss: 0.000282 \n",
      "w: -0.992846 b: 0.972583 loss: 0.000279 \n",
      "w: -0.992896 b: 0.972773 loss: 0.000275 \n",
      "w: -0.992945 b: 0.972962 loss: 0.000271 \n",
      "w: -0.992994 b: 0.973150 loss: 0.000267 \n",
      "w: -0.993042 b: 0.973336 loss: 0.000263 \n",
      "w: -0.993091 b: 0.973521 loss: 0.000260 \n",
      "w: -0.993139 b: 0.973705 loss: 0.000256 \n",
      "w: -0.993186 b: 0.973887 loss: 0.000253 \n",
      "w: -0.993234 b: 0.974069 loss: 0.000249 \n",
      "w: -0.993281 b: 0.974248 loss: 0.000246 \n",
      "w: -0.993327 b: 0.974427 loss: 0.000242 \n",
      "w: -0.993373 b: 0.974605 loss: 0.000239 \n",
      "w: -0.993419 b: 0.974781 loss: 0.000236 \n",
      "w: -0.993465 b: 0.974956 loss: 0.000232 \n",
      "w: -0.993510 b: 0.975130 loss: 0.000229 \n",
      "w: -0.993555 b: 0.975302 loss: 0.000226 \n",
      "w: -0.993600 b: 0.975473 loss: 0.000223 \n",
      "w: -0.993645 b: 0.975644 loss: 0.000220 \n",
      "w: -0.993689 b: 0.975813 loss: 0.000217 \n",
      "w: -0.993732 b: 0.975980 loss: 0.000214 \n",
      "w: -0.993776 b: 0.976147 loss: 0.000211 \n",
      "w: -0.993819 b: 0.976313 loss: 0.000208 \n",
      "w: -0.993862 b: 0.976477 loss: 0.000205 \n",
      "w: -0.993905 b: 0.976640 loss: 0.000202 \n",
      "w: -0.993947 b: 0.976802 loss: 0.000199 \n",
      "w: -0.993989 b: 0.976963 loss: 0.000197 \n",
      "w: -0.994031 b: 0.977123 loss: 0.000194 \n",
      "w: -0.994072 b: 0.977282 loss: 0.000191 \n",
      "w: -0.994113 b: 0.977439 loss: 0.000189 \n",
      "w: -0.994154 b: 0.977596 loss: 0.000186 \n",
      "w: -0.994195 b: 0.977751 loss: 0.000183 \n",
      "w: -0.994235 b: 0.977906 loss: 0.000181 \n",
      "w: -0.994275 b: 0.978059 loss: 0.000178 \n",
      "w: -0.994315 b: 0.978211 loss: 0.000176 \n",
      "w: -0.994354 b: 0.978362 loss: 0.000173 \n",
      "w: -0.994393 b: 0.978513 loss: 0.000171 \n",
      "w: -0.994432 b: 0.978662 loss: 0.000169 \n",
      "w: -0.994471 b: 0.978810 loss: 0.000166 \n",
      "w: -0.994509 b: 0.978957 loss: 0.000164 \n",
      "w: -0.994547 b: 0.979103 loss: 0.000162 \n",
      "w: -0.994585 b: 0.979248 loss: 0.000160 \n",
      "w: -0.994623 b: 0.979392 loss: 0.000157 \n",
      "w: -0.994660 b: 0.979535 loss: 0.000155 \n",
      "w: -0.994697 b: 0.979677 loss: 0.000153 \n",
      "w: -0.994734 b: 0.979818 loss: 0.000151 \n",
      "w: -0.994770 b: 0.979958 loss: 0.000149 \n",
      "w: -0.994807 b: 0.980097 loss: 0.000147 \n",
      "w: -0.994843 b: 0.980235 loss: 0.000145 \n",
      "w: -0.994878 b: 0.980372 loss: 0.000143 \n",
      "w: -0.994914 b: 0.980508 loss: 0.000141 \n",
      "w: -0.994949 b: 0.980643 loss: 0.000139 \n",
      "w: -0.994984 b: 0.980778 loss: 0.000137 \n",
      "w: -0.995019 b: 0.980911 loss: 0.000135 \n",
      "w: -0.995054 b: 0.981044 loss: 0.000133 \n",
      "w: -0.995088 b: 0.981175 loss: 0.000131 \n",
      "w: -0.995122 b: 0.981306 loss: 0.000129 \n",
      "w: -0.995156 b: 0.981435 loss: 0.000128 \n",
      "w: -0.995189 b: 0.981564 loss: 0.000126 \n",
      "w: -0.995223 b: 0.981692 loss: 0.000124 \n",
      "w: -0.995256 b: 0.981819 loss: 0.000122 \n",
      "w: -0.995289 b: 0.981945 loss: 0.000121 \n",
      "w: -0.995322 b: 0.982070 loss: 0.000119 \n",
      "w: -0.995354 b: 0.982195 loss: 0.000117 \n",
      "w: -0.995386 b: 0.982318 loss: 0.000116 \n",
      "w: -0.995418 b: 0.982441 loss: 0.000114 \n",
      "w: -0.995450 b: 0.982563 loss: 0.000113 \n",
      "w: -0.995482 b: 0.982684 loss: 0.000111 \n",
      "w: -0.995513 b: 0.982804 loss: 0.000110 \n",
      "w: -0.995544 b: 0.982923 loss: 0.000108 \n",
      "w: -0.995575 b: 0.983042 loss: 0.000107 \n",
      "w: -0.995606 b: 0.983159 loss: 0.000105 \n",
      "w: -0.995636 b: 0.983276 loss: 0.000104 \n",
      "w: -0.995667 b: 0.983392 loss: 0.000102 \n",
      "w: -0.995696 b: 0.983508 loss: 0.000101 \n",
      "w: -0.995726 b: 0.983622 loss: 0.000099 \n",
      "w: -0.995756 b: 0.983736 loss: 0.000098 \n",
      "w: -0.995785 b: 0.983848 loss: 0.000097 \n",
      "w: -0.995815 b: 0.983960 loss: 0.000095 \n",
      "w: -0.995844 b: 0.984072 loss: 0.000094 \n",
      "w: -0.995873 b: 0.984182 loss: 0.000093 \n",
      "w: -0.995901 b: 0.984292 loss: 0.000091 \n",
      "w: -0.995930 b: 0.984401 loss: 0.000090 \n",
      "w: -0.995958 b: 0.984509 loss: 0.000089 \n",
      "w: -0.995986 b: 0.984617 loss: 0.000088 \n",
      "w: -0.996014 b: 0.984723 loss: 0.000086 \n",
      "w: -0.996041 b: 0.984829 loss: 0.000085 \n",
      "w: -0.996069 b: 0.984935 loss: 0.000084 \n",
      "w: -0.996096 b: 0.985039 loss: 0.000083 \n",
      "w: -0.996123 b: 0.985143 loss: 0.000082 \n",
      "w: -0.996150 b: 0.985246 loss: 0.000081 \n",
      "w: -0.996177 b: 0.985348 loss: 0.000080 \n",
      "w: -0.996203 b: 0.985450 loss: 0.000078 \n",
      "w: -0.996230 b: 0.985551 loss: 0.000077 \n",
      "w: -0.996256 b: 0.985651 loss: 0.000076 \n",
      "w: -0.996282 b: 0.985751 loss: 0.000075 \n",
      "w: -0.996308 b: 0.985850 loss: 0.000074 \n",
      "w: -0.996333 b: 0.985948 loss: 0.000073 \n",
      "w: -0.996359 b: 0.986045 loss: 0.000072 \n",
      "w: -0.996384 b: 0.986142 loss: 0.000071 \n",
      "w: -0.996409 b: 0.986238 loss: 0.000070 \n",
      "w: -0.996434 b: 0.986334 loss: 0.000069 \n",
      "w: -0.996459 b: 0.986429 loss: 0.000068 \n",
      "w: -0.996483 b: 0.986523 loss: 0.000067 \n",
      "w: -0.996508 b: 0.986616 loss: 0.000066 \n",
      "w: -0.996532 b: 0.986709 loss: 0.000065 \n",
      "w: -0.996556 b: 0.986801 loss: 0.000065 \n",
      "w: -0.996580 b: 0.986893 loss: 0.000064 \n",
      "w: -0.996604 b: 0.986984 loss: 0.000063 \n",
      "w: -0.996627 b: 0.987074 loss: 0.000062 \n",
      "w: -0.996651 b: 0.987164 loss: 0.000061 \n",
      "w: -0.996674 b: 0.987253 loss: 0.000060 \n",
      "w: -0.996697 b: 0.987341 loss: 0.000059 \n",
      "w: -0.996720 b: 0.987429 loss: 0.000059 \n",
      "w: -0.996743 b: 0.987516 loss: 0.000058 \n",
      "w: -0.996765 b: 0.987603 loss: 0.000057 \n",
      "w: -0.996788 b: 0.987689 loss: 0.000056 \n",
      "w: -0.996810 b: 0.987774 loss: 0.000055 \n",
      "w: -0.996832 b: 0.987859 loss: 0.000055 \n",
      "w: -0.996854 b: 0.987943 loss: 0.000054 \n",
      "w: -0.996876 b: 0.988027 loss: 0.000053 \n",
      "w: -0.996898 b: 0.988110 loss: 0.000052 \n",
      "w: -0.996919 b: 0.988193 loss: 0.000052 \n",
      "w: -0.996940 b: 0.988275 loss: 0.000051 \n",
      "w: -0.996962 b: 0.988356 loss: 0.000050 \n",
      "w: -0.996983 b: 0.988437 loss: 0.000050 \n",
      "w: -0.997004 b: 0.988517 loss: 0.000049 \n",
      "w: -0.997024 b: 0.988597 loss: 0.000048 \n",
      "w: -0.997045 b: 0.988676 loss: 0.000048 \n",
      "w: -0.997066 b: 0.988754 loss: 0.000047 \n",
      "w: -0.997086 b: 0.988832 loss: 0.000046 \n",
      "w: -0.997106 b: 0.988910 loss: 0.000046 \n",
      "w: -0.997126 b: 0.988987 loss: 0.000045 \n",
      "w: -0.997146 b: 0.989063 loss: 0.000044 \n",
      "w: -0.997166 b: 0.989139 loss: 0.000044 \n",
      "w: -0.997186 b: 0.989214 loss: 0.000043 \n",
      "w: -0.997205 b: 0.989289 loss: 0.000043 \n",
      "w: -0.997225 b: 0.989364 loss: 0.000042 \n",
      "w: -0.997244 b: 0.989437 loss: 0.000041 \n",
      "w: -0.997263 b: 0.989511 loss: 0.000041 \n",
      "w: -0.997282 b: 0.989583 loss: 0.000040 \n",
      "w: -0.997301 b: 0.989656 loss: 0.000040 \n",
      "w: -0.997320 b: 0.989727 loss: 0.000039 \n",
      "w: -0.997338 b: 0.989799 loss: 0.000039 \n",
      "w: -0.997357 b: 0.989869 loss: 0.000038 \n",
      "w: -0.997375 b: 0.989940 loss: 0.000038 \n",
      "w: -0.997393 b: 0.990010 loss: 0.000037 \n",
      "w: -0.997411 b: 0.990079 loss: 0.000036 \n",
      "w: -0.997429 b: 0.990148 loss: 0.000036 \n",
      "w: -0.997447 b: 0.990216 loss: 0.000035 \n",
      "w: -0.997465 b: 0.990284 loss: 0.000035 \n",
      "w: -0.997482 b: 0.990351 loss: 0.000034 \n",
      "w: -0.997500 b: 0.990418 loss: 0.000034 \n",
      "w: -0.997517 b: 0.990485 loss: 0.000034 \n",
      "w: -0.997534 b: 0.990551 loss: 0.000033 \n",
      "w: -0.997551 b: 0.990616 loss: 0.000033 \n",
      "w: -0.997568 b: 0.990681 loss: 0.000032 \n",
      "w: -0.997585 b: 0.990746 loss: 0.000032 \n",
      "w: -0.997602 b: 0.990810 loss: 0.000031 \n",
      "w: -0.997619 b: 0.990874 loss: 0.000031 \n",
      "w: -0.997635 b: 0.990937 loss: 0.000030 \n",
      "w: -0.997652 b: 0.991000 loss: 0.000030 \n",
      "w: -0.997668 b: 0.991063 loss: 0.000030 \n",
      "w: -0.997684 b: 0.991125 loss: 0.000029 \n",
      "w: -0.997700 b: 0.991186 loss: 0.000029 \n",
      "w: -0.997716 b: 0.991247 loss: 0.000028 \n",
      "w: -0.997732 b: 0.991308 loss: 0.000028 \n",
      "w: -0.997748 b: 0.991369 loss: 0.000028 \n",
      "w: -0.997763 b: 0.991428 loss: 0.000027 \n",
      "w: -0.997779 b: 0.991488 loss: 0.000027 \n",
      "w: -0.997794 b: 0.991547 loss: 0.000026 \n",
      "w: -0.997810 b: 0.991606 loss: 0.000026 \n",
      "w: -0.997825 b: 0.991664 loss: 0.000026 \n",
      "w: -0.997840 b: 0.991722 loss: 0.000025 \n",
      "w: -0.997855 b: 0.991779 loss: 0.000025 \n",
      "w: -0.997870 b: 0.991836 loss: 0.000025 \n",
      "w: -0.997885 b: 0.991893 loss: 0.000024 \n",
      "w: -0.997899 b: 0.991949 loss: 0.000024 \n",
      "w: -0.997914 b: 0.992005 loss: 0.000024 \n",
      "w: -0.997928 b: 0.992060 loss: 0.000023 \n",
      "w: -0.997943 b: 0.992115 loss: 0.000023 \n",
      "w: -0.997957 b: 0.992170 loss: 0.000023 \n",
      "w: -0.997971 b: 0.992224 loss: 0.000022 \n",
      "w: -0.997985 b: 0.992278 loss: 0.000022 \n",
      "w: -0.997999 b: 0.992332 loss: 0.000022 \n",
      "w: -0.998013 b: 0.992385 loss: 0.000021 \n",
      "w: -0.998027 b: 0.992438 loss: 0.000021 \n",
      "w: -0.998040 b: 0.992490 loss: 0.000021 \n",
      "w: -0.998054 b: 0.992543 loss: 0.000021 \n",
      "w: -0.998068 b: 0.992594 loss: 0.000020 \n",
      "w: -0.998081 b: 0.992646 loss: 0.000020 \n",
      "w: -0.998094 b: 0.992697 loss: 0.000020 \n",
      "w: -0.998108 b: 0.992747 loss: 0.000019 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: -0.998121 b: 0.992798 loss: 0.000019 \n",
      "w: -0.998134 b: 0.992848 loss: 0.000019 \n",
      "w: -0.998147 b: 0.992897 loss: 0.000019 \n",
      "w: -0.998159 b: 0.992947 loss: 0.000018 \n",
      "w: -0.998172 b: 0.992995 loss: 0.000018 \n",
      "w: -0.998185 b: 0.993044 loss: 0.000018 \n",
      "w: -0.998197 b: 0.993092 loss: 0.000018 \n",
      "w: -0.998210 b: 0.993140 loss: 0.000017 \n",
      "w: -0.998222 b: 0.993188 loss: 0.000017 \n",
      "w: -0.998235 b: 0.993235 loss: 0.000017 \n",
      "w: -0.998247 b: 0.993282 loss: 0.000017 \n",
      "w: -0.998259 b: 0.993329 loss: 0.000016 \n",
      "w: -0.998271 b: 0.993375 loss: 0.000016 \n",
      "w: -0.998283 b: 0.993421 loss: 0.000016 \n",
      "w: -0.998295 b: 0.993467 loss: 0.000016 \n",
      "w: -0.998307 b: 0.993512 loss: 0.000016 \n",
      "w: -0.998319 b: 0.993557 loss: 0.000015 \n",
      "w: -0.998330 b: 0.993602 loss: 0.000015 \n",
      "w: -0.998342 b: 0.993646 loss: 0.000015 \n",
      "w: -0.998354 b: 0.993690 loss: 0.000015 \n",
      "w: -0.998365 b: 0.993734 loss: 0.000015 \n",
      "w: -0.998376 b: 0.993777 loss: 0.000014 \n",
      "w: -0.998388 b: 0.993821 loss: 0.000014 \n",
      "w: -0.998399 b: 0.993863 loss: 0.000014 \n",
      "w: -0.998410 b: 0.993906 loss: 0.000014 \n",
      "w: -0.998421 b: 0.993948 loss: 0.000014 \n",
      "w: -0.998432 b: 0.993990 loss: 0.000013 \n",
      "w: -0.998443 b: 0.994032 loss: 0.000013 \n",
      "w: -0.998453 b: 0.994073 loss: 0.000013 \n",
      "w: -0.998464 b: 0.994115 loss: 0.000013 \n",
      "w: -0.998475 b: 0.994155 loss: 0.000013 \n",
      "w: -0.998486 b: 0.994196 loss: 0.000012 \n",
      "w: -0.998496 b: 0.994236 loss: 0.000012 \n",
      "w: -0.998506 b: 0.994276 loss: 0.000012 \n",
      "w: -0.998517 b: 0.994316 loss: 0.000012 \n",
      "w: -0.998527 b: 0.994355 loss: 0.000012 \n",
      "w: -0.998537 b: 0.994394 loss: 0.000012 \n",
      "w: -0.998547 b: 0.994433 loss: 0.000011 \n",
      "w: -0.998558 b: 0.994472 loss: 0.000011 \n",
      "w: -0.998568 b: 0.994510 loss: 0.000011 \n",
      "w: -0.998578 b: 0.994548 loss: 0.000011 \n",
      "w: -0.998587 b: 0.994586 loss: 0.000011 \n",
      "w: -0.998597 b: 0.994624 loss: 0.000011 \n",
      "w: -0.998607 b: 0.994661 loss: 0.000011 \n",
      "w: -0.998617 b: 0.994698 loss: 0.000010 \n",
      "w: -0.998626 b: 0.994735 loss: 0.000010 \n",
      "w: -0.998636 b: 0.994772 loss: 0.000010 \n",
      "w: -0.998645 b: 0.994808 loss: 0.000010 \n",
      "w: -0.998655 b: 0.994844 loss: 0.000010 \n",
      "w: -0.998664 b: 0.994880 loss: 0.000010 \n",
      "w: -0.998673 b: 0.994915 loss: 0.000010 \n",
      "w: -0.998682 b: 0.994950 loss: 0.000009 \n",
      "w: -0.998692 b: 0.994986 loss: 0.000009 \n",
      "w: -0.998701 b: 0.995020 loss: 0.000009 \n",
      "w: -0.998710 b: 0.995055 loss: 0.000009 \n",
      "w: -0.998719 b: 0.995089 loss: 0.000009 \n",
      "w: -0.998728 b: 0.995123 loss: 0.000009 \n",
      "w: -0.998736 b: 0.995157 loss: 0.000009 \n",
      "w: -0.998745 b: 0.995191 loss: 0.000009 \n",
      "w: -0.998754 b: 0.995224 loss: 0.000008 \n",
      "w: -0.998762 b: 0.995257 loss: 0.000008 \n",
      "w: -0.998771 b: 0.995290 loss: 0.000008 \n",
      "w: -0.998780 b: 0.995323 loss: 0.000008 \n",
      "w: -0.998788 b: 0.995355 loss: 0.000008 \n",
      "w: -0.998796 b: 0.995388 loss: 0.000008 \n",
      "w: -0.998805 b: 0.995420 loss: 0.000008 \n",
      "w: -0.998813 b: 0.995451 loss: 0.000008 \n",
      "w: -0.998821 b: 0.995483 loss: 0.000008 \n",
      "w: -0.998829 b: 0.995514 loss: 0.000007 \n",
      "w: -0.998838 b: 0.995545 loss: 0.000007 \n",
      "w: -0.998846 b: 0.995576 loss: 0.000007 \n",
      "w: -0.998854 b: 0.995607 loss: 0.000007 \n",
      "w: -0.998862 b: 0.995637 loss: 0.000007 \n",
      "w: -0.998870 b: 0.995668 loss: 0.000007 \n",
      "w: -0.998877 b: 0.995698 loss: 0.000007 \n",
      "w: -0.998885 b: 0.995728 loss: 0.000007 \n",
      "w: -0.998893 b: 0.995757 loss: 0.000007 \n",
      "w: -0.998901 b: 0.995787 loss: 0.000007 \n",
      "w: -0.998908 b: 0.995816 loss: 0.000006 \n",
      "w: -0.998916 b: 0.995845 loss: 0.000006 \n",
      "w: -0.998923 b: 0.995874 loss: 0.000006 \n",
      "w: -0.998931 b: 0.995902 loss: 0.000006 \n",
      "w: -0.998938 b: 0.995931 loss: 0.000006 \n",
      "w: -0.998946 b: 0.995959 loss: 0.000006 \n",
      "w: -0.998953 b: 0.995987 loss: 0.000006 \n",
      "w: -0.998960 b: 0.996015 loss: 0.000006 \n",
      "w: -0.998967 b: 0.996042 loss: 0.000006 \n",
      "w: -0.998975 b: 0.996070 loss: 0.000006 \n",
      "w: -0.998982 b: 0.996097 loss: 0.000006 \n",
      "w: -0.998989 b: 0.996124 loss: 0.000006 \n",
      "w: -0.998996 b: 0.996151 loss: 0.000005 \n",
      "w: -0.999003 b: 0.996178 loss: 0.000005 \n",
      "w: -0.999010 b: 0.996204 loss: 0.000005 \n",
      "w: -0.999016 b: 0.996231 loss: 0.000005 \n",
      "w: -0.999023 b: 0.996257 loss: 0.000005 \n",
      "w: -0.999030 b: 0.996283 loss: 0.000005 \n",
      "w: -0.999037 b: 0.996309 loss: 0.000005 \n",
      "w: -0.999044 b: 0.996334 loss: 0.000005 \n",
      "w: -0.999050 b: 0.996360 loss: 0.000005 \n",
      "w: -0.999057 b: 0.996385 loss: 0.000005 \n",
      "w: -0.999063 b: 0.996410 loss: 0.000005 \n",
      "w: -0.999070 b: 0.996435 loss: 0.000005 \n",
      "w: -0.999076 b: 0.996460 loss: 0.000005 \n",
      "w: -0.999083 b: 0.996484 loss: 0.000005 \n",
      "w: -0.999089 b: 0.996509 loss: 0.000005 \n",
      "w: -0.999095 b: 0.996533 loss: 0.000004 \n",
      "w: -0.999102 b: 0.996557 loss: 0.000004 \n",
      "w: -0.999108 b: 0.996581 loss: 0.000004 \n",
      "w: -0.999114 b: 0.996605 loss: 0.000004 \n",
      "w: -0.999120 b: 0.996628 loss: 0.000004 \n",
      "w: -0.999126 b: 0.996651 loss: 0.000004 \n",
      "w: -0.999132 b: 0.996675 loss: 0.000004 \n",
      "w: -0.999138 b: 0.996698 loss: 0.000004 \n",
      "w: -0.999144 b: 0.996721 loss: 0.000004 \n",
      "w: -0.999150 b: 0.996743 loss: 0.000004 \n",
      "w: -0.999156 b: 0.996766 loss: 0.000004 \n",
      "w: -0.999162 b: 0.996789 loss: 0.000004 \n",
      "w: -0.999168 b: 0.996811 loss: 0.000004 \n",
      "w: -0.999174 b: 0.996833 loss: 0.000004 \n",
      "w: -0.999179 b: 0.996855 loss: 0.000004 \n",
      "w: -0.999185 b: 0.996877 loss: 0.000004 \n",
      "w: -0.999191 b: 0.996898 loss: 0.000004 \n",
      "w: -0.999196 b: 0.996920 loss: 0.000004 \n",
      "w: -0.999202 b: 0.996941 loss: 0.000003 \n",
      "w: -0.999207 b: 0.996962 loss: 0.000003 \n",
      "w: -0.999213 b: 0.996983 loss: 0.000003 \n",
      "w: -0.999218 b: 0.997004 loss: 0.000003 \n",
      "w: -0.999224 b: 0.997025 loss: 0.000003 \n",
      "w: -0.999229 b: 0.997046 loss: 0.000003 \n",
      "w: -0.999234 b: 0.997066 loss: 0.000003 \n",
      "w: -0.999240 b: 0.997087 loss: 0.000003 \n",
      "w: -0.999245 b: 0.997107 loss: 0.000003 \n",
      "w: -0.999250 b: 0.997127 loss: 0.000003 \n",
      "w: -0.999256 b: 0.997147 loss: 0.000003 \n",
      "w: -0.999261 b: 0.997167 loss: 0.000003 \n",
      "w: -0.999266 b: 0.997186 loss: 0.000003 \n",
      "w: -0.999271 b: 0.997206 loss: 0.000003 \n",
      "w: -0.999276 b: 0.997225 loss: 0.000003 \n",
      "w: -0.999281 b: 0.997244 loss: 0.000003 \n",
      "w: -0.999286 b: 0.997264 loss: 0.000003 \n",
      "w: -0.999291 b: 0.997283 loss: 0.000003 \n",
      "w: -0.999296 b: 0.997301 loss: 0.000003 \n",
      "w: -0.999301 b: 0.997320 loss: 0.000003 \n",
      "w: -0.999306 b: 0.997339 loss: 0.000003 \n",
      "w: -0.999310 b: 0.997357 loss: 0.000003 \n",
      "w: -0.999315 b: 0.997376 loss: 0.000003 \n",
      "w: -0.999320 b: 0.997394 loss: 0.000003 \n",
      "w: -0.999325 b: 0.997412 loss: 0.000002 \n",
      "w: -0.999329 b: 0.997430 loss: 0.000002 \n",
      "w: -0.999334 b: 0.997448 loss: 0.000002 \n",
      "w: -0.999339 b: 0.997465 loss: 0.000002 \n",
      "w: -0.999343 b: 0.997483 loss: 0.000002 \n",
      "w: -0.999348 b: 0.997500 loss: 0.000002 \n",
      "w: -0.999352 b: 0.997518 loss: 0.000002 \n",
      "w: -0.999357 b: 0.997535 loss: 0.000002 \n",
      "w: -0.999361 b: 0.997552 loss: 0.000002 \n",
      "w: -0.999366 b: 0.997569 loss: 0.000002 \n",
      "w: -0.999370 b: 0.997586 loss: 0.000002 \n",
      "w: -0.999374 b: 0.997603 loss: 0.000002 \n",
      "w: -0.999379 b: 0.997619 loss: 0.000002 \n",
      "w: -0.999383 b: 0.997636 loss: 0.000002 \n",
      "w: -0.999387 b: 0.997652 loss: 0.000002 \n",
      "w: -0.999392 b: 0.997668 loss: 0.000002 \n",
      "w: -0.999396 b: 0.997685 loss: 0.000002 \n",
      "w: -0.999400 b: 0.997701 loss: 0.000002 \n",
      "w: -0.999404 b: 0.997717 loss: 0.000002 \n",
      "w: -0.999408 b: 0.997733 loss: 0.000002 \n",
      "w: -0.999412 b: 0.997748 loss: 0.000002 \n",
      "w: -0.999417 b: 0.997764 loss: 0.000002 \n",
      "w: -0.999421 b: 0.997779 loss: 0.000002 \n",
      "w: -0.999425 b: 0.997795 loss: 0.000002 \n",
      "w: -0.999429 b: 0.997810 loss: 0.000002 \n",
      "w: -0.999433 b: 0.997825 loss: 0.000002 \n",
      "w: -0.999436 b: 0.997840 loss: 0.000002 \n",
      "w: -0.999440 b: 0.997855 loss: 0.000002 \n",
      "w: -0.999444 b: 0.997870 loss: 0.000002 \n",
      "w: -0.999448 b: 0.997885 loss: 0.000002 \n",
      "w: -0.999452 b: 0.997900 loss: 0.000002 \n",
      "w: -0.999456 b: 0.997914 loss: 0.000002 \n",
      "w: -0.999460 b: 0.997929 loss: 0.000002 \n",
      "w: -0.999463 b: 0.997943 loss: 0.000002 \n",
      "w: -0.999467 b: 0.997957 loss: 0.000002 \n",
      "w: -0.999471 b: 0.997972 loss: 0.000002 \n",
      "w: -0.999474 b: 0.997986 loss: 0.000002 \n",
      "w: -0.999478 b: 0.998000 loss: 0.000001 \n",
      "w: -0.999482 b: 0.998013 loss: 0.000001 \n",
      "w: -0.999485 b: 0.998027 loss: 0.000001 \n",
      "w: -0.999489 b: 0.998041 loss: 0.000001 \n",
      "w: -0.999492 b: 0.998055 loss: 0.000001 \n",
      "w: -0.999496 b: 0.998068 loss: 0.000001 \n",
      "w: -0.999499 b: 0.998081 loss: 0.000001 \n",
      "w: -0.999503 b: 0.998095 loss: 0.000001 \n",
      "w: -0.999506 b: 0.998108 loss: 0.000001 \n",
      "w: -0.999510 b: 0.998121 loss: 0.000001 \n",
      "w: -0.999513 b: 0.998134 loss: 0.000001 \n",
      "w: -0.999517 b: 0.998147 loss: 0.000001 \n",
      "w: -0.999520 b: 0.998160 loss: 0.000001 \n",
      "w: -0.999523 b: 0.998173 loss: 0.000001 \n",
      "w: -0.999527 b: 0.998185 loss: 0.000001 \n",
      "w: -0.999530 b: 0.998198 loss: 0.000001 \n",
      "w: -0.999533 b: 0.998210 loss: 0.000001 \n",
      "w: -0.999536 b: 0.998223 loss: 0.000001 \n",
      "w: -0.999539 b: 0.998235 loss: 0.000001 \n",
      "w: -0.999543 b: 0.998247 loss: 0.000001 \n",
      "w: -0.999546 b: 0.998260 loss: 0.000001 \n",
      "w: -0.999549 b: 0.998272 loss: 0.000001 \n",
      "w: -0.999552 b: 0.998284 loss: 0.000001 \n",
      "w: -0.999555 b: 0.998296 loss: 0.000001 \n",
      "w: -0.999558 b: 0.998307 loss: 0.000001 \n",
      "w: -0.999561 b: 0.998319 loss: 0.000001 \n",
      "w: -0.999564 b: 0.998331 loss: 0.000001 \n",
      "w: -0.999568 b: 0.998342 loss: 0.000001 \n",
      "w: -0.999570 b: 0.998354 loss: 0.000001 \n",
      "w: -0.999573 b: 0.998365 loss: 0.000001 \n",
      "w: -0.999576 b: 0.998377 loss: 0.000001 \n",
      "w: -0.999579 b: 0.998388 loss: 0.000001 \n",
      "w: -0.999582 b: 0.998399 loss: 0.000001 \n",
      "w: -0.999585 b: 0.998410 loss: 0.000001 \n",
      "w: -0.999588 b: 0.998421 loss: 0.000001 \n",
      "w: -0.999591 b: 0.998432 loss: 0.000001 \n",
      "w: -0.999594 b: 0.998443 loss: 0.000001 \n",
      "w: -0.999597 b: 0.998454 loss: 0.000001 \n",
      "w: -0.999599 b: 0.998465 loss: 0.000001 \n",
      "w: -0.999602 b: 0.998475 loss: 0.000001 \n",
      "w: -0.999605 b: 0.998486 loss: 0.000001 \n",
      "w: -0.999608 b: 0.998496 loss: 0.000001 \n",
      "w: -0.999610 b: 0.998507 loss: 0.000001 \n",
      "w: -0.999613 b: 0.998517 loss: 0.000001 \n",
      "w: -0.999616 b: 0.998527 loss: 0.000001 \n",
      "w: -0.999618 b: 0.998538 loss: 0.000001 \n",
      "w: -0.999621 b: 0.998548 loss: 0.000001 \n",
      "w: -0.999624 b: 0.998558 loss: 0.000001 \n",
      "w: -0.999626 b: 0.998568 loss: 0.000001 \n",
      "w: -0.999629 b: 0.998578 loss: 0.000001 \n",
      "w: -0.999631 b: 0.998588 loss: 0.000001 \n",
      "w: -0.999634 b: 0.998598 loss: 0.000001 \n",
      "w: -0.999637 b: 0.998607 loss: 0.000001 \n",
      "w: -0.999639 b: 0.998617 loss: 0.000001 \n",
      "w: -0.999642 b: 0.998626 loss: 0.000001 \n",
      "w: -0.999644 b: 0.998636 loss: 0.000001 \n",
      "w: -0.999647 b: 0.998645 loss: 0.000001 \n",
      "w: -0.999649 b: 0.998655 loss: 0.000001 \n",
      "w: -0.999651 b: 0.998664 loss: 0.000001 \n",
      "w: -0.999654 b: 0.998673 loss: 0.000001 \n",
      "w: -0.999656 b: 0.998683 loss: 0.000001 \n",
      "w: -0.999659 b: 0.998692 loss: 0.000001 \n",
      "w: -0.999661 b: 0.998701 loss: 0.000001 \n",
      "w: -0.999663 b: 0.998710 loss: 0.000001 \n",
      "w: -0.999666 b: 0.998719 loss: 0.000001 \n",
      "w: -0.999668 b: 0.998728 loss: 0.000001 \n",
      "w: -0.999670 b: 0.998737 loss: 0.000001 \n",
      "w: -0.999673 b: 0.998745 loss: 0.000001 \n",
      "w: -0.999675 b: 0.998754 loss: 0.000001 \n",
      "w: -0.999677 b: 0.998763 loss: 0.000001 \n",
      "w: -0.999679 b: 0.998771 loss: 0.000001 \n",
      "w: -0.999682 b: 0.998780 loss: 0.000001 \n",
      "w: -0.999684 b: 0.998788 loss: 0.000001 \n",
      "w: -0.999686 b: 0.998797 loss: 0.000001 \n",
      "w: -0.999688 b: 0.998805 loss: 0.000001 \n",
      "w: -0.999690 b: 0.998813 loss: 0.000001 \n",
      "w: -0.999692 b: 0.998821 loss: 0.000001 \n",
      "w: -0.999695 b: 0.998830 loss: 0.000001 \n",
      "w: -0.999697 b: 0.998838 loss: 0.000001 \n",
      "w: -0.999699 b: 0.998846 loss: 0.000000 \n",
      "w: -0.999701 b: 0.998854 loss: 0.000000 \n",
      "w: -0.999703 b: 0.998862 loss: 0.000000 \n",
      "w: -0.999705 b: 0.998870 loss: 0.000000 \n",
      "w: -0.999707 b: 0.998878 loss: 0.000000 \n",
      "w: -0.999709 b: 0.998885 loss: 0.000000 \n",
      "w: -0.999711 b: 0.998893 loss: 0.000000 \n",
      "w: -0.999713 b: 0.998901 loss: 0.000000 \n",
      "w: -0.999715 b: 0.998908 loss: 0.000000 \n",
      "w: -0.999717 b: 0.998916 loss: 0.000000 \n",
      "w: -0.999719 b: 0.998923 loss: 0.000000 \n",
      "w: -0.999721 b: 0.998931 loss: 0.000000 \n",
      "w: -0.999723 b: 0.998938 loss: 0.000000 \n",
      "w: -0.999725 b: 0.998946 loss: 0.000000 \n",
      "w: -0.999727 b: 0.998953 loss: 0.000000 \n",
      "w: -0.999729 b: 0.998960 loss: 0.000000 \n",
      "w: -0.999731 b: 0.998968 loss: 0.000000 \n",
      "w: -0.999732 b: 0.998975 loss: 0.000000 \n",
      "w: -0.999734 b: 0.998982 loss: 0.000000 \n",
      "w: -0.999736 b: 0.998989 loss: 0.000000 \n",
      "w: -0.999738 b: 0.998996 loss: 0.000000 \n",
      "w: -0.999740 b: 0.999003 loss: 0.000000 \n",
      "w: -0.999742 b: 0.999010 loss: 0.000000 \n",
      "w: -0.999743 b: 0.999017 loss: 0.000000 \n",
      "w: -0.999745 b: 0.999023 loss: 0.000000 \n",
      "w: -0.999747 b: 0.999030 loss: 0.000000 \n",
      "w: -0.999749 b: 0.999037 loss: 0.000000 \n",
      "w: -0.999750 b: 0.999044 loss: 0.000000 \n",
      "w: -0.999752 b: 0.999050 loss: 0.000000 \n",
      "w: -0.999754 b: 0.999057 loss: 0.000000 \n",
      "w: -0.999756 b: 0.999063 loss: 0.000000 \n",
      "w: -0.999757 b: 0.999070 loss: 0.000000 \n",
      "w: -0.999759 b: 0.999076 loss: 0.000000 \n",
      "w: -0.999761 b: 0.999083 loss: 0.000000 \n",
      "w: -0.999762 b: 0.999089 loss: 0.000000 \n",
      "w: -0.999764 b: 0.999095 loss: 0.000000 \n",
      "w: -0.999766 b: 0.999102 loss: 0.000000 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "        \n",
    "    for i in range(training_epoch):\n",
    "        sess.run(train, feed_dict={X:x,Y:y})\n",
    "           \n",
    "        # evaluate training accuracy\n",
    "        curr_w, curr_b, curr_loss  = sess.run([w, b, loss], {X:x,Y:y})\n",
    "        print('w: %f b: %f loss: %f '%(curr_w, curr_b, curr_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.27608234434506596&quot;).pbtxt = 'node {\\n  name: &quot;weight/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;weight&quot;\\n  input: &quot;weight/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;weight/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;weight&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.30000001192092896\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bias&quot;\\n  input: &quot;bias/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;weight/read&quot;\\n  input: &quot;X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;mul&quot;\\n  input: &quot;bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;add&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;range/start&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;gradients/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;range&quot;\\n  input: &quot;gradients/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients/Sum_grad/add&quot;\\n  input: &quot;gradients/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients/Sum_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;gradients/Sum_grad/range/start&quot;\\n  input: &quot;gradients/Sum_grad/Size&quot;\\n  input: &quot;gradients/Sum_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Sum_grad/Shape_1&quot;\\n  input: &quot;gradients/Sum_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;gradients/Sum_grad/range&quot;\\n  input: &quot;gradients/Sum_grad/mod&quot;\\n  input: &quot;gradients/Sum_grad/Shape&quot;\\n  input: &quot;gradients/Sum_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Sum_grad/DynamicStitch&quot;\\n  input: &quot;gradients/Sum_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Sum_grad/Shape&quot;\\n  input: &quot;gradients/Sum_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Sum_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Sum_grad/Reshape&quot;\\n  input: &quot;gradients/Sum_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Sum_grad/Tile&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  input: &quot;X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;weight/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul_1&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_weight/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;weight&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_weight/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;gradients_1/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients_1/Shape&quot;\\n  input: &quot;gradients_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;gradients_1/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;range&quot;\\n  input: &quot;gradients_1/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;gradients_1/Sum_grad/add&quot;\\n  input: &quot;gradients_1/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;gradients_1/Sum_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;gradients_1/Sum_grad/range/start&quot;\\n  input: &quot;gradients_1/Sum_grad/Size&quot;\\n  input: &quot;gradients_1/Sum_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients_1/Sum_grad/Shape_1&quot;\\n  input: &quot;gradients_1/Sum_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;gradients_1/Sum_grad/range&quot;\\n  input: &quot;gradients_1/Sum_grad/mod&quot;\\n  input: &quot;gradients_1/Sum_grad/Shape&quot;\\n  input: &quot;gradients_1/Sum_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients_1/Sum_grad/DynamicStitch&quot;\\n  input: &quot;gradients_1/Sum_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients_1/Sum_grad/Shape&quot;\\n  input: &quot;gradients_1/Sum_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/Fill&quot;\\n  input: &quot;gradients_1/Sum_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients_1/Sum_grad/Reshape&quot;\\n  input: &quot;gradients_1/Sum_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients_1/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients_1/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients_1/Sum_grad/Tile&quot;\\n  input: &quot;gradients_1/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients_1/sub_grad/Shape&quot;\\n  input: &quot;gradients_1/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/Square_grad/mul_1&quot;\\n  input: &quot;gradients_1/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/sub_grad/Sum&quot;\\n  input: &quot;gradients_1/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/Square_grad/mul_1&quot;\\n  input: &quot;gradients_1/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients_1/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/sub_grad/Neg&quot;\\n  input: &quot;gradients_1/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients_1/sub_grad/Reshape&quot;\\n  input: &quot;^gradients_1/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/sub_grad/Reshape&quot;\\n  input: &quot;^gradients_1/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients_1/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients_1/add_grad/Shape&quot;\\n  input: &quot;gradients_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/add_grad/Sum&quot;\\n  input: &quot;gradients_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/add_grad/Sum_1&quot;\\n  input: &quot;gradients_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients_1/mul_grad/Shape&quot;\\n  input: &quot;gradients_1/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;X&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/mul_grad/mul&quot;\\n  input: &quot;gradients_1/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/mul_grad/Sum&quot;\\n  input: &quot;gradients_1/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;weight/read&quot;\\n  input: &quot;gradients_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients_1/mul_grad/mul_1&quot;\\n  input: &quot;gradients_1/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients_1/mul_grad/Sum_1&quot;\\n  input: &quot;gradients_1/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients_1/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/mul_grad/Reshape&quot;\\n  input: &quot;^gradients_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients_1/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients_1/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent_1/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent_1/update_weight/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;weight&quot;\\n  input: &quot;GradientDescent_1/learning_rate&quot;\\n  input: &quot;gradients_1/mul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@weight&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent_1/update_bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;bias&quot;\\n  input: &quot;GradientDescent_1/learning_rate&quot;\\n  input: &quot;gradients_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent_1&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent_1/update_weight/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent_1/update_bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^weight/Assign&quot;\\n  input: &quot;^bias/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.27608234434506596&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#call to display TensorBoard\n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
