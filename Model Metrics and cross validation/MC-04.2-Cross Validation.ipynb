{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://thecads.org/wp-content/uploads/2017/02/adax_logo.jpg)\n",
    "# Module 4.2: Cross-Validation\n",
    "\n",
    "When performing machine learning, NEVER learn the parameters of a prediction function and test it on the SAME data. This is a big mistake! You can say that: the machine has already \"seen\" the data before, hence we still don't know how it will perform with DIFFERENT data.\n",
    "\n",
    "A model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. To avoid this \"over-estimation\" of performance, it is a common practice when performing a supervised machine learning experiment to hold out part of the available data as a test set: (X_test, y_test) that we have seen so far. Note that the word \"experiment\" is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. A mini \"experiment\" is required to try mimic how your machine learning algorithm would perform in a real-world scenario later on.\n",
    "\n",
    "In scikit-learn, a random split into training and test sets can be quickly computed with the `train_test_split` helper function as we have seen many times before. \n",
    "\n",
    "### \"Validation set\" still necessary?\n",
    "\n",
    "When evaluating different hyperparameters for estimators, such as the `C` setting in an SVM, there is a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally on it. We call this a \"leaking\" of knowledge about the test set into the model; hence the evaluation metrics no longer report correctly. To better mimic a real world scenario, we need to hold out another part of the dataset: the so-called \"validation set\". Train as per the norm, the finding of the best hyperparameters is done on the validation set, and when the best settings are found, evaluation can be done on the test set.\n",
    "\n",
    "However, by partitioning the available data into three sets (training, validation, test), we drastically reduce the number of samples which can be used for learning the model. Also, results can quite dependent on a particular random choice for the pair of (train, validation) sets. \n",
    "\n",
    "A solution to this problem is a procedure called **cross-validation** (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called *k-fold CV*, the training set is split into *k* smaller sets. The following procedure is followed for each of the k \"folds\": A model is trained using *k-1* of the folds as training data, and the resulting model is validated on the remaining part of the data (i.e. which is now technically the test set) to compute a performance measure such as accuracy.\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is the average of the values computed across all *k* folds. This approach can be computationally expensive, but does not waste too much data. If you have a huge dataset, perhaps partitioning into (training, validation, test) sets can still be done, since k-fold cross-validation may take much longer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction, feature selection, refine feature, analysis,algorithm, 3 fold separation, model complexity graph, pick model, validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation metrics\n",
    "\n",
    "The simplest way to use cross-validation is to call the `cross_val_score` helper function on the estimator and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(boston_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n",
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print(boston_data.target.shape)\n",
    "print(boston_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(boston_data.data, boston_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(boston_data.data, boston_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current score is shows about 74% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the `score` method of the estimator. It is possible to change this by using the `scoring` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77394825, 0.61303844, 0.76186955, 0.8420353 , 0.84853554])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "scores = cross_val_score(model_1, \n",
    "                         boston_data.data[0:350,:], \n",
    "                         boston_data.target[0:350], \n",
    "                         cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678854152393214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(model_1, \n",
    "                              boston_data.data[0:350,:], \n",
    "                              boston_data.target[0:350], \n",
    "                              cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.48780759, 24.29443347, 32.61693771, 30.20079915, 31.17121248,\n",
       "       24.059746  , 20.71807435, 20.11603889, 13.98882323, 18.28335327,\n",
       "       21.68471144, 19.1752468 , 20.73323431, 18.24115884, 18.4833574 ,\n",
       "       17.605247  , 20.52053384, 17.92764171, 14.27339046, 16.70045176,\n",
       "       13.92823872, 17.85731943, 19.85675971, 15.71258095, 16.51644069,\n",
       "       12.54829078, 15.02134466, 16.83703369, 21.99592011, 24.57824577,\n",
       "       14.44925088, 18.79373171, 15.76834831, 15.05571585, 17.72485992,\n",
       "       20.46980443, 19.56673052, 20.37586274, 22.13543492, 29.41291561,\n",
       "       33.90965299, 31.04445342, 25.10577047, 25.60995593, 22.41614892,\n",
       "       19.89975693, 20.71207861, 19.61355773, 12.37379776, 16.41307852,\n",
       "       20.74226257, 21.49449747, 27.53828092, 22.47284425, 13.88645936,\n",
       "       33.14982468, 22.27062189, 30.01402364, 20.31197787, 18.26952929,\n",
       "       15.09181898, 16.10471867, 22.12697192, 25.176828  , 27.52345441,\n",
       "       26.11130673, 20.40367728, 19.10781263, 15.53314423, 18.70718841,\n",
       "       27.6298008 , 22.46344175, 24.46103158, 25.90762348, 26.4983916 ,\n",
       "       24.1982646 , 22.88341195, 23.18521636, 22.45247596, 20.86595951,\n",
       "       29.36640355, 26.49038736, 25.25581264, 23.13639508, 25.96881817,\n",
       "       28.46753307, 22.64657785, 24.27077797, 31.40900784, 33.11321102,\n",
       "       26.70248387, 26.30761565, 29.24140432, 28.33673486, 26.22156303,\n",
       "       28.46078343, 23.73852979, 42.28871022, 41.6454971 , 36.47432485,\n",
       "       26.18842083, 27.13854502, 17.06199522, 20.00956527, 20.51450155,\n",
       "       17.2260377 , 17.05542934, 20.44007264, 23.14395355, 20.7075428 ,\n",
       "       21.91617306, 27.07215702, 18.7877744 , 20.19701857, 22.92766963,\n",
       "       18.19204708, 22.11746307, 20.35323688, 18.2115659 , 18.0238821 ,\n",
       "       24.57952775, 25.07665907, 24.10780321, 22.35194216, 23.34515416,\n",
       "       25.10553313, 20.14458581, 15.86264288, 23.02313365, 15.65201285,\n",
       "       23.14633687, 22.50847975, 22.29371113, 16.52688333, 13.9563654 ,\n",
       "       21.80999886, 17.9679176 , 23.25649126, 17.09815559, 20.47302666,\n",
       "       18.78889396,  7.98803013, 17.12066034, 16.61961857, 11.40838673,\n",
       "       20.87923025, 15.6348774 , 11.61725536, 13.83918537, 17.45776952,\n",
       "       22.06638817, 14.75408864, 12.92008937, 17.19993286, 22.81365248,\n",
       "       22.19412813, 11.83758974, 28.43966405, 19.98245822, 25.15941475,\n",
       "       23.18170192, 34.06446787, 37.75685206, 43.43050458, 18.6679194 ,\n",
       "       19.71820503, 37.884903  , 18.31876557, 22.17126902, 23.21078948,\n",
       "       17.7755444 , 18.16735829, 16.79408153, 24.91051969, 20.65901418,\n",
       "       29.2549362 , 23.11487382, 24.13777794, 29.52570982, 32.39268306,\n",
       "       38.23005475, 24.47093064, 31.72911932, 25.80069235, 17.18846416,\n",
       "       23.6298248 , 40.51064508, 29.84834906, 27.83390156, 33.26745151,\n",
       "       30.72760822, 28.13949872, 32.58803852, 31.38017464, 28.72145215,\n",
       "       42.16403234, 34.31894137, 32.20574526, 33.93588994, 29.87203659,\n",
       "       31.38149103, 22.9990299 , 38.26559884, 42.74673045, 44.51206235,\n",
       "       22.46159091, 24.16333027, 17.74004869, 22.39179072, 13.32697284,\n",
       "       21.6287967 , 16.34150339, 22.06880103, 26.09256762, 15.5664299 ,\n",
       "       24.12737929, 24.63938155, 28.33639562, 23.67530465, 27.9306892 ,\n",
       "       34.16926145, 25.29587218, 33.72358486, 29.26696357, 44.8761909 ,\n",
       "       49.08654548, 42.36291461, 33.89629571, 41.15217768, 30.76221239,\n",
       "       22.53618136, 36.05890383, 45.15758247, 44.04699964, 31.78765898,\n",
       "       23.55519794, 30.37497757, 35.55436397, 27.72517878, 27.95676497,\n",
       "       29.69693844, 21.81380993, 23.66757535, 26.47297923, 12.49116231,\n",
       "       12.391762  , 19.5670014 , 18.45499127, 21.76584342, 26.30183061,\n",
       "       24.88516017, 24.62206477, 27.78690236, 40.28780771, 20.44620172,\n",
       "       18.48976853, 38.39544022, 52.09696517, 38.47274285, 34.05671875,\n",
       "       37.5058716 , 40.31235232, 48.29098207, 38.37418635, 37.47797951,\n",
       "       23.35353282, 35.15756766, 48.71047597, 41.67433766, 23.85913826,\n",
       "       21.39330936, 26.65250527, 28.16191251, 41.06955988, 34.64728126,\n",
       "       32.74972077, 37.56392882, 34.45652893, 29.33347716, 35.28750707,\n",
       "       41.8009403 , 34.94099875, 40.56754358, 45.94744528, 34.22434989,\n",
       "       27.08874141, 21.38533817, 25.24202386, 25.44890422, 28.15071918,\n",
       "       33.00305156, 35.60940282, 30.99972379, 25.81230122, 23.38017674,\n",
       "       29.98368566, 27.56863176, 19.27856046, 26.65875811, 33.4536685 ,\n",
       "       30.26330052, 29.14293911, 29.32798208, 34.28059615, 36.14550636,\n",
       "       30.18918207, 37.35137563, 32.08107283, 27.4758527 , 21.23357065,\n",
       "       16.50505617, 25.21721994, 20.98582993, 23.49642667, 25.63158858,\n",
       "       17.65477612, 18.4057192 , 18.03992941, 24.93614255, 22.30057534,\n",
       "       25.18887174, 24.69847145, 21.84482581, 17.03155383, 25.83958915,\n",
       "       26.40360213, 24.71343752, 21.10548695, 19.83832155, 24.60135812,\n",
       "       21.17353029, 18.95410872, 22.08580617, 23.08524698, 22.86804404,\n",
       "       21.08179619, 19.55206339, 18.6211277 , 22.24848698, 21.08956436,\n",
       "       20.35716563, 33.03026901, 22.95117737, 27.27738092, 29.66230076,\n",
       "       17.0377086 , 15.25350633, 25.28978364, 27.81462006, 25.93520143])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207953282687247"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(boston_data.target[0:350], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77394825, 0.61303844, 0.76186955, 0.8420353 , 0.84853554])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_1,boston_data.data[0:350,:], \n",
    "                        boston_data.target[0:350], \n",
    "                        cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boston_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what is *f1_macro* under scoring parameter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Sidetrack: Performance metrics\n",
    "\n",
    "Before moving any further, it is essential to have some basic understanding of performance metrics, what are the different types out there, and which are normally used.\n",
    "\n",
    "For classification tasks, the **Accuracy** measure is by far the most commonly used. The `score` method usually returns this as well for classification-based estimators. The concept of Accuracy is an easy one: The number of correctly classified test samples over the total number of test samples. However, Accuracy only makes a lot of sense if the class distribution in the dataset is more or less equal. \n",
    "\n",
    "Example: Imagine if you have a dataset containing 90% normal emails and 10% spam. Your classifier returns an Accuracy score of 90%. You *could* be classifying all 90% of the emails correctly, and none of the spam correctly! That wouldn't make a very good spam classifier, isn't it? In this case, your classifier is *actually* performing perfect (100%) on the normal class, while flunking (0%) the entire spam class. Averaging across both classes, you can say realistically, your classifier is performing at about 50%. You could figure this out with common sense, but it appears that Accuracy is not the best measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "model_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868421052631579\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        13\n",
      " versicolor       1.00      0.69      0.81        16\n",
      "  virginica       0.64      1.00      0.78         9\n",
      "\n",
      "avg / total       0.92      0.87      0.87        38\n",
      "\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 11  5]\n",
      " [ 0  0  9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21e3496bf98>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e3496ba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, \n",
    "                                                    iris.target, \n",
    "                                                    random_state=0)\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred = model_2.predict(X_test)\n",
    "y_true = y_test\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print()\n",
    "print(confusion_matrix(y_true, y_pred, labels=[0, 1, 2]))\n",
    "\n",
    "# seaborn to put on some clothes!\n",
    "cmat = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "sns.heatmap(cmat/np.sum(cmat,axis=1), \n",
    "            annot=True, \n",
    "            xticklabels=target_names, \n",
    "            yticklabels=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight difference in the Accuracy and F1-score. Usually, these two metrics will be very different if there is *class imbalance*. Class imbalance occurs in a dataset when it has a non-equal class distribution of samples. In such cases, the F1-score offers a more accurate reflection of the performance than Accuracy.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png)\n",
    "\n",
    "The confusion table's rows represent the actual (desired) labels, while the columns represent the predicted labels. Basically this means the diagonals contain the number of correctly predicted labels (actual label and predicted label the same), while the other cells indicate the incorrectly predicted samples.\n",
    "\n",
    "Precision is the number of true positives over the items that have been selected (predicted labels). Recall is the number of true positives over items that are relevant (desired labels). F1-score is the geometric mean of Precision and Recall, which means it is somewhere at the average of the two values. In an imbalance dataset, the Recall and Precision values can be very far apart, hence F1-score provides an average of that. Use the confusion matrix to verify your understanding of Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Cross Validation\n",
    "\n",
    "One could argue that the `train_test_split` does a good job of evaluating the model by holding out some of the dataset for testing. One disadvantage of using a holdout set for model validation is that we have lost a portion of our data to the model training. This is not optimal, and can cause problems – especially if the initial set of training data is small.\n",
    "\n",
    "One way to address this is to use cross-validation; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set. Visually, it might look something like this:\n",
    "\n",
    "![](resources/5-fold-CV.png)\n",
    "\n",
    "Here we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data. This would be rather tedious to do by hand, and so we can use Scikit-Learn's cross_val_score convenience routine to do it succinctly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63861069,  0.71334432,  0.58645134,  0.07842495, -0.26312455])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, \n",
    "                         boston_data.data, \n",
    "                         boston_data.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cv argument is an integer, `cross_val_score` uses the `KFold` or `StratifiedKFold` strategies by default. It is also possible to use other cross validation strategies by passing a cross validation iterator instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88888889, 0.97777778, 0.86666667])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit #good for shuffle\n",
    "\n",
    "n_samples = iris.data.shape[0]\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "cross_val_score(model_2, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ShuffleSplit` performs random splits on the dataset for cross-validation. This does not guarantee that all folds will be different! But  this is still very likely (to have folds with different samples) for sizeable datasets. Default test size is set to 0.1 by default, so it makes sense for this to work if you have a huge dataset and are just sampling 10% to be test set with only a few splits (like the example above).\n",
    "\n",
    "### Essential consideration for preprocessing\n",
    "\n",
    "Just as it is important to test a predictor on data held-out from training, preprocessing steps (such as standardization, feature selection, etc.) and data transformations should similarly be learnt from a training set and applied to held-out data for prediction as well. Instead of doing this manually, you can use the `Pipeline` feature which makes it easier to compose estimators, providing all these steps under cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82222222, 0.86666667, 0.86666667])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), \n",
    "                        model_2)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures that the `StandardScaler` is applied within the cross-validation loop for both the training data and test data that is partitioned internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple metrics\n",
    "\n",
    "The `cross_validate` function differs from `cross_val_score` in two ways - 1) It allows specifying multiple metrics for evaluation, 2) It returns a `dict` containing training scores, fit-times and score-times in addition to the test score, which gives us a whole array of performance-related information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "[0.01562786 0.         0.         0.         0.00099611]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.datasets import load_iris\n",
    "#iris = load_iris()\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0) # this example uses Support Vector Machine\n",
    "scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,\n",
    "                        cv=5, return_train_score=False)\n",
    "\n",
    "print(sorted(scores.keys()))\n",
    "print(scores['test_recall_macro'] ) \n",
    "print(scores['fit_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Iterators\n",
    "\n",
    "**KFold** divides all the samples in k groups of samples, called folds of equal sizes (if possible). The prediction function is learned using k - 1 folds, and the fold left out is used for test.\n",
    "\n",
    "**RepeatedKFold** repeats K-Fold n times. It can be used when one requires to run KFold n times, producing different splits in each repetition.\n",
    "\n",
    "**LeaveOneOut** (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for n samples, we have n different training sets and n different tests set. This cross-validation procedure does not waste much data as only one sample is removed from the training set. But there are obvious drawbacks: It is computationally expensive since it needs n folds, rather than k folds of KFold. In terms of accuracy, LOO often results in high variance as an estimator for the test error. As such, the reported accuracy is always an over-estimate (too good to be true).\n",
    "\n",
    "**StratifiedKFold** is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set. This is a very good thing to do especially if your dataset has class imbalance. You do not want to sample too much from a particular large class, which might cause the smaller classes to be poorly sampled for training purposes. This will have an undesirable effect on the training. Hence, the importance to use stratified folds.\n",
    "\n",
    "**StratifiedShuffleSplit** is a variation of `ShuffleSplit`, which returns stratified splits but randomly sampled, i.e which creates splits by preserving the same percentage for each target class as in the complete set.\n",
    "\n",
    "See the documentation on how to use these iterators. You can try some of them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also cross-validation iterators for grouped data. \n",
    "\n",
    "The underlying generative process (like data collection) can yield groups of dependent samples.\n",
    "\n",
    "Such a grouping of data is domain specific. For example, medical data that has been collected from multiple patients, with multiple samples taken from each patient. Such data is likely to be dependent on the individual group. In this case, the patient id for each sample will be its group identifier. Experimentally, we would like to know if a model trained on a particular set of group generalizes well to other unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the training fold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Mini\" Kaggle Project\n",
    "\n",
    "What you have learned so far (ML algorithms, ensemble methods, cross-validation techniques) would be sufficient to equip you towards working on a mini machine learning project from start to end. Basically, you should now be familiar with the entire framework or \"experimental pipeline\" required to pre-process, learn models, perform predictions and measure performance.\n",
    "\n",
    "Two larger datasets are suggested here (choose one!), both of which are from Kaggle playground:\n",
    "* Leaf classification: [https://www.kaggle.com/c/leaf-classification](https://www.kaggle.com/c/leaf-classification)\n",
    "* Pima Indians Diabetes classification: [https://www.kaggle.com/uciml/pima-indians-diabetes-database](https://www.kaggle.com/uciml/pima-indians-diabetes-database) \n",
    "\n",
    "Or if you are really ambitious, why not just try both! \n",
    "\n",
    "At the end of the project, you are encouraged to make a submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
